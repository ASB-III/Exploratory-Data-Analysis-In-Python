{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Prior to Fitting a Regression Model\n",
    "### Learn about recommended EDA steps before fitting a regression model.\n",
    "\n",
    "# Introduction\n",
    "Before fitting any model, it is often important to conduct EDA in order to check assumptions, inspect the data for anomalies (such as missing, duplicated, or mis-coded data), and inform feature selection/transformation. In this article, we will explore some of the EDA techniques that are generally employed prior to fitting a regression model.\n",
    "\n",
    "# The data\n",
    "For our example analysis, we’ve downloaded a dataset from Kaggle which contains data on MLB games from the 2016 season. We’ve saved this data as a dataframe named bb. Suppose that we want to fit a linear regression to predict attendance using the following predictors:\n",
    "\n",
    "- game_type — is the game during the day or at night\n",
    "- day_of_week — what day of the week did the game occur\n",
    "- temperature — average game temperature (Fahrenheit)\n",
    "- sky — description of sky condition at the time of the game\n",
    "- total_runs — total runs scored in the game\n",
    "# Preview the dataset\n",
    "Any EDA process will probably begin by inspecting a subset of data. For a Pandas dataframe, this can be done by using the .head() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tattendance\tgame_type\tday_of_week\ttemperature\tsky\ttotal_runs\n",
    "0\t40030.0\tNight Game\tSunday\t74\tSunny\t7\n",
    "1\t21621.0\tNight Game\tWednesday\t55\tOvercast\t5\n",
    "2\t12622.0\tNight Game\tWednesday\t48\tUnknown\t6\n",
    "3\t18531.0\tNight Game\tWednesday\t65\tCloudy\t4\n",
    "4\t18572.0\tDay Game\tWednesday\t77\tIn Dome\t7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the first few rows of the data, we can often figure out what kind of data we have (eg., discrete or continuous) and get a sense of how they are coded. For example, we can see that attendance, temperature, and total_runs are numbers, while game_type, day_of_week, and sky appear to be text.\n",
    "\n",
    "After our initial inspection, we’ll want to dig deeper to investigate the following:\n",
    "\n",
    "- the data type of each variable\n",
    "- how discrete/categorical data is coded (and whether we need to make any changes)\n",
    "- how the data are scaled\n",
    "- whether there is missing data and how it is coded\n",
    "- whether there are outliers\n",
    "- the distributions of continuous features\n",
    "- the relationships between pairs of features\n",
    "# Data types\n",
    "It is important to check the data type for each feature. The quantitative variables should be read in as numbers — either int64 or float64 — and categorical variables should be stored as strings (columns of strings have a dtype of object because of how they are stored in Python). We can check data types of columns in a Pandas dataframe using .dtypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attendance     float64\n",
    "game_type       object\n",
    "day_of_week     object\n",
    "temperature     object\n",
    "sky             object\n",
    "total_runs      object\n",
    "dtype: object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this output, we can see that temperature and total_runs are both quantitative variables but were read in as object dtypes. This can happen when there is a non-numeric character — such as a letter or punctuation symbol — in the same column. We would need to explore further in order to figure out what’s going on. For example, we might inspect a different set of rows and see the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attendance\tgame_type\tday_of_week\ttemperature\tsky\ttotal_runs\n",
    "5\t12757.0\tNight Game\tTuesday\t72\tIn Dome\t5\n",
    "6\t28329.0\tNight Game\tTuesday\t70\tUnknown\t-\n",
    "7\t26049.0\tNight Game\tTuesday\tUnknown\tSunny\t11\n",
    "8\t10478.0\tNight Game\tTuesda\t70\tNaN\t9\n",
    "9\t47820.0\tDay Game\tTuesday\t36\tSunny\t8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that temperature has missing data coded as Unknown rather than NaN. If we fit a regression on this data as is, we will end up treating temperature as a categorical variable and therefore fitting separate slopes for every value of temperature; instead, we probably want a single slope. To fix this, we’ll need to replace every Unknown with some other value (or remove them from the data altogether) and recode the temperature column as an int.\n",
    "\n",
    "# Categorical encoding\n",
    "EDA is also important during the feature engineering process in order to inform decisions around categorical encoding. This is important because categorical features with many levels are “expensive” to include in a regression model (we need to calculate a separate slope for each level). If one of the levels has only a few observations, we might want to delete those records from the data before fitting the model. We can check this using .value_counts():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb['game_type'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Night Game    1664\n",
    "Day Game       799\n",
    "Name: game_type, dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the output, we can see here that there are two levels for game_type; about one-third of games are day games and two-thirds are night games.\n",
    "\n",
    "The .value_counts() accessor can also illuminate other issues. For example, in the following output, we notice that one instance of 'Tuesday' was miscoded as Tuesda. This can either be corrected or removed before proceeding with a regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb['day_of_week'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Saturday     396\n",
    "Friday       394\n",
    "Sunday       392\n",
    "Wednesday    379\n",
    "Tuesday      375\n",
    "Monday       278\n",
    "Thursday     248\n",
    "Tuesda         1\n",
    "Name: day_of_week, dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few different options for how we might want to code the day_of_week variable. If attendance increases approximately linearly throughout the week, we might argue that day_of_week is ordinal and code it as an int in our model. However, attendance goes up and down throughout the week, we’re better off leaving it as an unordered category (str). Finally, if we see that games on Friday-Sunday simply have higher attendance than other days of the week, we might re-code this feature to only have two levels: Weekend and Weekday. We can check this by using boxplots:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://static-assets.codecademy.com/Courses/EDA/day_of_week_order_boxplot.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that attendance on Friday, Saturday, and Sunday is on average higher than the other days of the week. Therefore it may be beneficial to re-code this feature to either Weekend or Weekday.\n",
    "\n",
    "# Scaling\n",
    "For quantitative features, it is important to think about how each feature is scaled. Some features will be on vastly different scales than others just based on the nature of what the feature is measuring. For example, let’s look at temperature and total_runs using the .describe() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "         attendance      temperature    total_runs\n",
    "count    2457.000000     2457.000000    2457.000000\n",
    "mean     30380.462352    73.834959      8.949187\n",
    "std      9874.626652     10.567219      4.579542\n",
    "min      8766.000000     31.000000      1.000000\n",
    "25%      22437.000000    67.000000      6.000000\n",
    "50%      30628.000000    74.000000      8.000000\n",
    "75%      38412.000000    81.000000      12.000000\n",
    "max      54449.000000    101.000000     60.000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two features are on different scales because what they are measuring are different (temperature is in degrees Fahrenheit, total_runs is the number of runs scored in a game). Because of this, the ranges of values and the standard deviations for each are very different from one another. We can see here that temperature has a standard deviation of about 10.57, while total_runs has a standard deviation of about 4.58.\n",
    "\n",
    "When working with features with largely differing scales, it is often a good idea to standardize the features so that they all have a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "A feature without any values close to zero may also make it more difficult to estimate and interpret the intercept of a regression model. Standardizing or otherwise re-scaling the feature can fix this issue.\n",
    "\n",
    "# Missing data\n",
    "When we initially inspected the data, we saw some evidence that missing data is coded in a few different ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attendance\tgame_type\tday_of_week\ttemperature\tsky\ttotal_runs\n",
    "5\t12757.0\tNight Game\tTuesday\t72\tIn Dome\t5\n",
    "6\t28329.0\tNight Game\tTuesday\t70\tUnknown\t-\n",
    "7\t26049.0\tNight Game\tTuesday\tUnknown\tSunny\t11\n",
    "8\t10478.0\tNight Game\tTuesda\t70\tNaN\t9\n",
    "9\t47820.0\tDay Game\tTuesday\t36\tSunny\t8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, temperature uses the term Unknown, sky uses both Unknown and NaN, and total_runs has - to represent a missing value. The observations with missing values will either have to be removed or replaced (with an imputed value or missing data type that Python can recognize, such as np.NaN) in order to proceed with fitting a regression model.\n",
    "\n",
    "# Outliers\n",
    "In our EDA, it is important to check for outliers and skew in the data. One way to check for outliers is to use scatter plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb.plot.scatter(x = 'total_runs',y = 'attendance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://static-assets.codecademy.com/Courses/EDA/outlier.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that there is one instance where the total runs in a single game is about 60, which is much larger than in the other games. Depending on the situation, we may first want to verify that this value is correct, then we can decide whether or not to remove it prior to fitting the model.\n",
    "\n",
    "# Distributions and associations\n",
    "Prior to fitting a linear regression model, it can be important to inspect the distributions of quantitative features and investigate the relationships between features. We can visually inspect both of these by using a pair plot:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://static-assets.codecademy.com/Courses/EDA/pairplot.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the histograms along the diagonal, total_runs appears to be somewhat right-skewed. This indicates that we may want to transform this feature to make it more normally distributed.\n",
    "\n",
    "We can explore the relationships between pairs of features by looking at the scatterplots off of the diagonal. This is useful for a few different reasons. For example, if we see non-linear associations between any of the predictors and the outcome variable, that might lead us to test out polynomial terms in our model. We can also get a sense for which features are most highly related to our outcome variable and check for collinearity. In this example, there appears to be a slight positive linear association between temperature and the total number of runs. We can further investigate this using a heat map of the correlation matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://static-assets.codecademy.com/Courses/EDA/heat_map.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a correlation of 0.35 between temperature and the total number of runs. This is not large enough to cause concern; however, if two or more predictors are highly correlated, we may consider leaving only one in our analysis. On the other hand, features that are highly correlated with our outcome variable are especially important to include in the model.\n",
    "\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "Let’s review the ways we were able to explore this data set in preparation for a regression model:\n",
    "\n",
    "\n",
    "- We previewed the first few rows of the data set using the .head() method.\n",
    "- We checked the data type of each variable in the data set using .dtypes and corrected variables with incorrect data types.\n",
    "- We investigated our categorical data to inform categorical encoding\n",
    "- We investigated the scale of our quantitative variables and considered whether standardizing/scaling might be appropriate\n",
    "- We investigated missing data\n",
    "- We checked for outliers\n",
    "- We inspected the distributions of our quantitative variables\n",
    "- We looked at the relationships between pairs of features using both scatter plots and box plots\n",
    "\n",
    "\n",
    "By going through these steps, we are more prepared to make decisions about feature selection/engineering and have learned valuable information about how to build a more accurate predictive model."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "126de395fc5ab05c9b404d5156ac230f2dc2d73638f7037ba66d30fa539ce6ef"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
